{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 准备工作\n",
    "\n",
    "智谱API申请，大家可以请前往 https://open.bigmodel.cn/ 申请智谱API\n",
    "\n",
    "安装 Milvus 向量库\n",
    "\n",
    "### 基础环境\n",
    "\n",
    "* python 3.9.6\n",
    "* nodejs v18.17.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Milvus 向量数据库\n",
    "\n",
    "Milvus 是一个高度灵活、可靠且速度极快的云原生开源向量数据库。它为 embedding 相似性搜索和 AI 应用程序提供支持，并努力使每个组织都可以访问向量数据库。 Milvus 可以存储、索引和管理由深度神经网络和其他机器学习（ML）模型生成的十亿级别以上的 embedding 向量。\n",
    "它具备高可用、高性能、易拓展的特点，用于海量向量数据的实时召回。\n",
    "\n",
    "### 为什么选择使用 Milvus\n",
    "* 高性能：性能高超，可对海量数据集进行向量相似度检索。\n",
    "* 高可用、高可靠：Milvus 支持在云上扩展，其容灾能力能够保证服务高可用。\n",
    "* 混合查询：Milvus 支持在向量相似度检索过程中进行标量字段过滤，实现混合查询。\n",
    "* 开发者友好：支持多语言、多工具的 Milvus 生态系统。\n",
    "\n",
    "安装 Milvus 请参考 https://milvus.io/docs/install_standalone-docker.md 官方文档\n",
    "\n",
    "当前使用版本 <span style=\"color: red\">v2.2.11</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LangChain\n",
    "\n",
    "LangChain 是一个开源框架，用于构建基于大型语言模型（LLM）的应用程序。LLM 是基于大量数据预先训练的大型深度学习模型，可以生成对用户查询的响应，例如回答问题或根据基于文本的提示创建图像。LangChain 提供各种工具和抽象，以提高模型生成的信息的定制性、准确性和相关性。例如，开发人员可以使用 LangChain 组件来构建新的提示链或自定义现有模板。LangChain 还包括一些组件，可让 LLM 无需重新训练即可访问新的数据集。\n",
    "\n",
    "当前项目使用了 LangChain 中的文档加载器、ChatZhipuAI 组件。LangChain 已经对接了智谱的大语言模型，可以直接使用。\n",
    "\n",
    "当前使用版本 <span style=\"color: red\">0.1.17</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 创建 Milvus 向量库数据集和写入向量数据\n",
    "\n",
    "首先需要在向量数据库中创建集合并添加索引"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymilvus import Collection, FieldSchema, DataType, CollectionSchema, connections\n",
    "\n",
    "connections.connect(alias='main', host=\"127.0.0.1\", port=19530)\n",
    "\n",
    "def create_index():\n",
    "    fields = [\n",
    "        FieldSchema(name=\"id\", dtype=DataType.INT64, is_primary=True, auto_id=True),\n",
    "        FieldSchema(name=\"document_ebm\", dtype=DataType.FLOAT_VECTOR, dim=1024),\n",
    "        FieldSchema(name=\"document_text\", dtype=DataType.VARCHAR, max_length=65535),\n",
    "    ]\n",
    "    schema = CollectionSchema(fields=fields)\n",
    "    # 创建集合\n",
    "    collection = Collection(name='documents', schema=schema, using='main')\n",
    "    # 添加索引\n",
    "    index_params = {\n",
    "        \"index_type\": \"HNSW\",\n",
    "        \"metric_type\": \"IP\",\n",
    "        \"params\": {\n",
    "            \"M\": 32,\n",
    "            \"efConstruction\": 512\n",
    "        }\n",
    "    }\n",
    "    collection.create_index(\n",
    "        field_name=\"document_ebm\",\n",
    "        index_params=index_params\n",
    "    )\n",
    "\n",
    "    collection.create_index(\n",
    "        field_name=\"document_text\",\n",
    "        index_params={\n",
    "            \"index_type\": \"marisa-trie\"\n",
    "        }\n",
    "    )\n",
    "    # 将数据加载到内存中\n",
    "    collection.load()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HNSW 索引类型\n",
    "HNSW 是一种基于图的索引算法。它按照一定的规则为图像构建多层导航结构。在这种结构中，上层更加稀疏，节点之间的距离更远；较低的层更密集，节点之间的距离更近。搜索从最上层开始，找到本层中距离目标最近的节点，然后进入下一层开始另一次搜索。经过多次迭代，可以快速逼近目标位置。\n",
    "\n",
    "为了提高性能，HNSW 将图每层节点的最大度数限制为 M 。此外，还可以使用 efConstruction （构建索引时）或 ef （搜索目标时）指定搜索范围。\n",
    "\n",
    "使用场景\n",
    "* 非常高速的查询\n",
    "* 要求召回率尽可能高\n",
    "* 大内存资源\n",
    "\n",
    "HNSW 索引params参数\n",
    "* M 节点的最大度数 (2, 2048)\n",
    "* efConstruction 索引时间内最近邻居的动态列表的大小。较高的 efConstruction 可能会提高索引质量，但代价是增加索引时间。(1, int_max)\n",
    "\n",
    "### IP （内积）\n",
    "两个嵌入之间的IP距离"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 将文档转换成向量\n",
    "\n",
    "这里利用 langchain 框架的文档加载器来加载需要的文档资源"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import DirectoryLoader\n",
    "\n",
    "def loadDocumentation(path: str, glob: str = \"*.text\"):\n",
    "    \"\"\"读取目录下指定文件\"\"\"\n",
    "    loader = DirectoryLoader(path=path, glob=glob)\n",
    "    return loader.load()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "调用智谱AI向量模型将文本转换成Embedding，并将转换后的Embedding写入到Milvus 向量数据库中。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from zhipuai import ZhipuAI\n",
    "from pymilvus import Collection, connections\n",
    "import os\n",
    "\n",
    "ZHIPUAI_API_KEY = os.environ.get('ZHIPUAI_API_KEY') # 替换成您自己的 key\n",
    "client = ZhipuAI(api_key=ZHIPUAI_API_KEY)\n",
    "\n",
    "connections.connect(alias='main', host=\"127.0.0.1\", port=19530)\n",
    "collection = Collection(name='documents', using='main')\n",
    "\n",
    "\n",
    "def documentEmbedding(docs):\n",
    "    document_ebm = []\n",
    "    document_text = []\n",
    "    for doc in docs:\n",
    "        embedding = getEmbedding(doc.page_content)\n",
    "        document_ebm.append(embedding)\n",
    "        document_text.append(doc.page_content)\n",
    "\n",
    "    documents = [document_ebm, document_text]\n",
    "    # 批量写入数据\n",
    "    res = collection.insert(data=documents)\n",
    "    collection.flush()\n",
    "    # 打印结果\n",
    "    print(f\"插入行数 -> {res.insert_count}\")\n",
    "\n",
    "\n",
    "def getEmbedding(text):\n",
    "    \"\"\" 调用智谱的 embedding-2 模型，将文本转换成 embedding 结果 \"\"\"\n",
    "    response = client.embeddings.create(\n",
    "        model=\"embedding-2\",\n",
    "        input=text,\n",
    "    )\n",
    "    return response.data[0].embedding\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # 读取文档\n",
    "    docs = loadDocumentation(\"./text/\", \"*.text\")\n",
    "    documentEmbedding(docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 根据提出的问题在向量库中查找最相似的结果\n",
    "Milvus 中的向量相似度搜索会计算查询向量与具有指定相似度度量的集合中的向量之间的距离，并返回最相似的结果。通过指定过滤标量字段或主键字段的布尔表达式，您可以执行混合搜索。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "首先将问题调用智谱的 embedding-2 模型，将问题转成 embedding，再利用问题的 embedding 去向量库中查询最相似的结果，返回 topk 1 个结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getDocuments(question: str):\n",
    "    query_vector = getEmbedding(question)\n",
    "    search_params = {\"metric_type\": \"IP\", \"params\": {\"nprobe\": 16}, \"offset\": 0}\n",
    "    results = collection.search(data=[query_vector], anns_field='document_ebm', param=search_params, limit=1, output_fields=['document_text'])\n",
    "    documents = []\n",
    "    for result in results:\n",
    "        for r in result:\n",
    "            document_text = str(r.entity.get('document_text'))\n",
    "            documents.append(document_text)\n",
    "\n",
    "    return documents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "langchain 已经集成了智谱的API接口，只需要导入 ChatZhipuAI \n",
    "\n",
    "定义AI的 prompt\n",
    "\n",
    "* System prompt \"\"\"请根据以下内容回答提出的问题，不要使用自身知识回答问题，回答的越详细越好\"\"\" AI 会根据自身的知识库来回答提出的问题，在 System prompt 中拒绝AI自身的回答\n",
    "* User prompt \"\"\"请基于以下内容:\n",
    "\\\"\\\"\\\"\n",
    "{context}\n",
    "\\\"\\\"\\\"\n",
    "来回答用户提出的问题，请用中文回答。\n",
    "\n",
    "问题: {question}\"\"\"\n",
    "\n",
    "使用 HumanMessagePromptTemplate 模版对象，传入 question 和 context，生成 user 的 prompt\n",
    "\n",
    "调用智谱的AI模型，得到流式输出结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.callbacks import AsyncIteratorCallbackHandler\n",
    "from langchain_community.chat_models import ChatZhipuAI\n",
    "from langchain_core.callbacks.manager import CallbackManager\n",
    "from langchain_core.messages import SystemMessage\n",
    "from langchain.prompts import HumanMessagePromptTemplate\n",
    "import asyncio\n",
    "import json\n",
    "\n",
    "async def sse_chat_bot(query: str):\n",
    "    documents = getDocuments(query)\n",
    "    print(\"查询到的文档\")\n",
    "    print(f\"\\033[92m{documents}\\033[0m\")\n",
    "    callback = AsyncIteratorCallbackHandler()\n",
    "    streaming_chat = ChatZhipuAI(\n",
    "        model=\"glm-3-turbo\",\n",
    "        api_key=ZHIPUAI_API_KEY,\n",
    "        temperature=0.01,\n",
    "        streaming=True,\n",
    "        callback_manager=CallbackManager([callback]),\n",
    "    )\n",
    "    # 定义问题模版\n",
    "    general_user_template = general_user_template = \"\"\"\n",
    "请基于以下内容:\n",
    "\\\"\\\"\\\"\n",
    "{context}\n",
    "\\\"\\\"\\\"\n",
    "来回答用户提出的问题，请用中文回答。\n",
    "\n",
    "问题: {question}\"\"\"\n",
    "\n",
    "    human_message = HumanMessagePromptTemplate.from_template(general_user_template, input_variables=[\"question\", \"context\"])\n",
    "    messages = [\n",
    "        SystemMessage(content=\"请根据以下内容回答提出的问题，不要使用自身知识回答问题，回答的越详细越好\"),\n",
    "        human_message.format(question=query, context='/n'.join(documents)),\n",
    "    ]\n",
    "\n",
    "    agenerate = streaming_chat.agenerate([messages])\n",
    "    finalAnswer = asyncio.create_task(agenerate)\n",
    "    async for token in callback.aiter():\n",
    "        yield json.dumps({\n",
    "            'output': token,\n",
    "            'end': False\n",
    "        }, ensure_ascii=False)\n",
    "\n",
    "    result = await finalAnswer\n",
    "\n",
    "    yield json.dumps({\n",
    "        'output': result.generations[0][0].text,\n",
    "        'end': True\n",
    "    }, ensure_ascii=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Demo 演示\n",
    "\n",
    "可以前往 https://github.com/zxing258974/RagDemo 下载当前演示项目的源码\n",
    "\n",
    "本项目使用了前后端分离，前端使用了 VUE3 ，位于 RagPage/ 目录下。后端使用了 FastApi 框架。更多的项目信息可以参考 README.md 文件"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
