大模型第一次达到了「类人」水平，用户可以用自然语言与计算机进行交流了。那么为了达到事半功倍的效果，我们就要精进提问的技巧，这便是Prompt Engineering。如何做呢？要把大模型视为精通某一领域的专业顾问，要以与专业顾问（比如导游，咨询师）对话的角度来看待问题。
比如说马上五一假期了，想要去上海玩，你问大模型『五一假期去上海玩，推荐一些行程』，大模型肯定会给你一个中规中矩的万能日程。这不能怪大模型，如果你如此问一个导游，负责的导游会直接反问你一大堆细节问题，因为这是行程所必须的；或者也是随便推荐一些大家都知道的地方。但肯定 是没有参考价值的。
为了达到最好的「沟通」效果，避免「Garbage In, Garbage Out」，就需要：
视为在与专业人士对话，也就是要拟定大模型的角色
一次对话尽可能的专注于一个问题或者一个主题
把问题描述清楚，需要的关键要素都列清楚，比如时间，地点人物，关键事件等等
限定问题，也就是说要尽可能多的补充问题细节，限定问题需要的回答，比如说可以做什么，不可以做什么，需要什么是时间点
恰当的分隔，要多多使用标点符号对提问进行分隔，这样更有利于大模型抓住重点
可以发现，这其实是沟通的技巧，抛开大模型，我们与正常的人沟通时，不也应该这样做吗？平时里的闲聊除外，正式的与人沟通时也应该使用这些技巧以达到最好的沟通效果。所以，最先需要掌握就是沟通技巧中的提问技巧。
继续我们上面的问题，使用上面的方法来优化提示：『五一假期，从南京出发，坐高铁，目的地上海，亲子3日游，不去迪士尼，不去动物园，安排详细行程』。这回得到的回答肯定有更大的参考价值。
大语言模型较以往的AI最大的进步在于超长的上下文记忆能力，这是它能达到「类人」水平的最主要的原因。那么在与大模型进行对话的时候，就要及时的补充上下文信息。一方面，你不可能一次性的把提问信息全都写全写对，那么一旦想到新的提示，就要及时的给到大模型；另外一方面，大模型有时候会胡编乱造，甚至胡言乱语（大模型都有一个叫做温度temperature的参数以控制这方面的行为），这并不是bug，而是语言创造力的一个体现。那么，一旦发现大模型跑偏了，就需要及时提供新的提示，补充上下文信息，对大模型进行纠正。
另外，就是如果感觉问题不太好理解，或者对输出有特殊的要求，还有一个补充上下文的办法就是给一个输出的示例，大模型是能够很好的捕获这一点的，并且这个对让大模型输出优质的回答非常有帮助。
不用担心溢出哈（就是输入字数太多，导致大模型理解不了），都4202年了，现在的大模型的上下文能力至少在4096个Token以上，对于大部分的常规问题来说足够了。